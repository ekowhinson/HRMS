# ─────────────────────────────────────────────────────────────────────────────
# Scheduled Maintenance – Security audits, backup verification, key rotation
# ─────────────────────────────────────────────────────────────────────────────
name: Scheduled Maintenance

on:
  schedule:
    - cron: "0 6 * * 1"   # Weekly: Monday 6:00 UTC – dependency audits
    - cron: "0 8 * * *"   # Daily: 8:00 UTC – backup verification
    - cron: "0 9 1 * *"   # Monthly: 1st at 9:00 UTC – key rotation check
  workflow_dispatch:
    inputs:
      task:
        description: "Task to run"
        required: true
        type: choice
        options:
          - dependency-audit
          - backup-verification
          - key-rotation-check
          - all

permissions:
  contents: read
  issues: write
  id-token: write

env:
  GCP_REGION: ${{ vars.GCP_REGION || 'us-central1' }}

jobs:
  # ── Weekly: Dependency Vulnerability Audit ──────────────────────────────
  dependency-audit:
    name: Dependency Audit
    runs-on: ubuntu-latest
    if: >-
      github.event_name == 'workflow_dispatch' &&
        (inputs.task == 'dependency-audit' || inputs.task == 'all') ||
      github.event.schedule == '0 6 * * 1'
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: npm
          cache-dependency-path: HRMS/frontend/package-lock.json

      - name: Python dependency audit
        id: pip-audit
        continue-on-error: true
        run: |
          pip install pip-audit
          cd HRMS/backend
          pip-audit -r requirements.txt --desc --format=json > /tmp/pip-audit.json 2>&1 || true
          VULN_COUNT=$(python3 -c "import json; data=json.load(open('/tmp/pip-audit.json')); print(len(data.get('dependencies', [])))" 2>/dev/null || echo "0")
          echo "vulns=$VULN_COUNT" >> "$GITHUB_OUTPUT"

          # Human-readable output
          pip-audit -r requirements.txt --desc > /tmp/pip-audit.txt 2>&1 || true
          cat /tmp/pip-audit.txt

      - name: Node dependency audit
        id: npm-audit
        continue-on-error: true
        run: |
          cd HRMS/frontend
          npm ci
          npm audit --json > /tmp/npm-audit.json 2>&1 || true
          HIGH_COUNT=$(python3 -c "
          import json
          data = json.load(open('/tmp/npm-audit.json'))
          vulns = data.get('metadata', {}).get('vulnerabilities', {})
          print(vulns.get('high', 0) + vulns.get('critical', 0))
          " 2>/dev/null || echo "0")
          echo "vulns=$HIGH_COUNT" >> "$GITHUB_OUTPUT"

          npm audit --audit-level=high || true

      - name: Create issue if vulnerabilities found
        if: steps.pip-audit.outputs.vulns != '0' || steps.npm-audit.outputs.vulns != '0'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          PIP_VULNS="${{ steps.pip-audit.outputs.vulns }}"
          NPM_VULNS="${{ steps.npm-audit.outputs.vulns }}"

          BODY="## Dependency Vulnerability Report

          **Date:** $(date -u +%Y-%m-%d)
          **Python vulnerabilities:** ${PIP_VULNS:-0}
          **Node.js high/critical vulnerabilities:** ${NPM_VULNS:-0}

          ### Python (pip-audit)
          \`\`\`
          $(cat /tmp/pip-audit.txt 2>/dev/null || echo 'No output')
          \`\`\`

          ### Node.js (npm audit)
          \`\`\`
          $(cd HRMS/frontend && npm audit --audit-level=high 2>&1 || echo 'No output')
          \`\`\`

          ---
          *Generated by [Scheduled Maintenance](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})*"

          # Check if an open issue already exists
          EXISTING=$(gh issue list --label "security" --state open --json number --jq '.[0].number' 2>/dev/null || echo "")

          if [ -n "$EXISTING" ]; then
            gh issue comment "$EXISTING" --body "$BODY"
            echo "Updated existing issue #${EXISTING}"
          else
            gh issue create \
              --title "Security: Dependency vulnerabilities detected ($(date +%Y-%m-%d))" \
              --body "$BODY" \
              --label "security,dependencies"
          fi

  # ── Daily: Backup Verification ─────────────────────────────────────────
  backup-verification:
    name: Verify Production Backups
    runs-on: ubuntu-latest
    if: >-
      github.event_name == 'workflow_dispatch' &&
        (inputs.task == 'backup-verification' || inputs.task == 'all') ||
      github.event.schedule == '0 8 * * *'
    steps:
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Check Cloud SQL backups
        id: backup-check
        run: |
          PROJECT="${{ secrets.GCP_PROJECT_ID_PRODUCTION }}"

          # Find the production DB instance
          INSTANCE=$(gcloud sql instances list \
            --project="$PROJECT" \
            --filter="name~nhia-hrms-production-pg" \
            --format="value(name)" \
            --limit=1 2>/dev/null || echo "")

          if [ -z "$INSTANCE" ]; then
            echo "WARNING: No production Cloud SQL instance found."
            echo "status=skip" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Get most recent backup
          LATEST_BACKUP=$(gcloud sql backups list \
            --instance="$INSTANCE" \
            --project="$PROJECT" \
            --sort-by="~startTime" \
            --limit=1 \
            --format="json" 2>/dev/null || echo "[]")

          BACKUP_TIME=$(echo "$LATEST_BACKUP" | python3 -c "
          import json, sys
          data = json.load(sys.stdin)
          print(data[0]['startTime'] if data else 'NONE')
          " 2>/dev/null || echo "NONE")

          BACKUP_STATUS=$(echo "$LATEST_BACKUP" | python3 -c "
          import json, sys
          data = json.load(sys.stdin)
          print(data[0].get('status', 'UNKNOWN') if data else 'NONE')
          " 2>/dev/null || echo "NONE")

          echo "## Backup Verification" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Instance:** ${INSTANCE}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Latest backup:** ${BACKUP_TIME}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Status:** ${BACKUP_STATUS}" >> "$GITHUB_STEP_SUMMARY"

          if [ "$BACKUP_TIME" = "NONE" ]; then
            echo "status=fail" >> "$GITHUB_OUTPUT"
            echo "**ALERT:** No backups found!" >> "$GITHUB_STEP_SUMMARY"
          elif [ "$BACKUP_STATUS" != "SUCCESSFUL" ]; then
            echo "status=fail" >> "$GITHUB_OUTPUT"
            echo "**ALERT:** Latest backup status: ${BACKUP_STATUS}" >> "$GITHUB_STEP_SUMMARY"
          else
            # Check if backup is less than 25 hours old
            BACKUP_EPOCH=$(date -d "$BACKUP_TIME" +%s 2>/dev/null || echo "0")
            NOW_EPOCH=$(date +%s)
            AGE_HOURS=$(( (NOW_EPOCH - BACKUP_EPOCH) / 3600 ))

            if [ "$AGE_HOURS" -gt 25 ]; then
              echo "status=fail" >> "$GITHUB_OUTPUT"
              echo "**ALERT:** Latest backup is ${AGE_HOURS} hours old (>25h)" >> "$GITHUB_STEP_SUMMARY"
            else
              echo "status=pass" >> "$GITHUB_OUTPUT"
              echo "Backup is ${AGE_HOURS} hours old — within expected window." >> "$GITHUB_STEP_SUMMARY"
            fi
          fi

      - name: Alert on backup failure
        if: steps.backup-check.outputs.status == 'fail'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh issue create \
            --title "ALERT: Production backup verification failed ($(date +%Y-%m-%d))" \
            --body "Production Cloud SQL backup verification failed. Check the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details." \
            --label "alert,database" \
            --repo "${{ github.repository }}" || true

  # ── Monthly: Service Account Key Rotation Check ────────────────────────
  key-rotation-check:
    name: Key Rotation Check
    runs-on: ubuntu-latest
    if: >-
      github.event_name == 'workflow_dispatch' &&
        (inputs.task == 'key-rotation-check' || inputs.task == 'all') ||
      github.event.schedule == '0 9 1 * *'
    steps:
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Check for old service account keys
        run: |
          echo "## Service Account Key Audit" >> "$GITHUB_STEP_SUMMARY"

          for PROJECT in "${{ secrets.GCP_PROJECT_ID_STAGING }}" "${{ secrets.GCP_PROJECT_ID_PRODUCTION }}"; do
            [ -z "$PROJECT" ] && continue

            echo "### Project: ${PROJECT}" >> "$GITHUB_STEP_SUMMARY"

            SA_LIST=$(gcloud iam service-accounts list \
              --project="$PROJECT" \
              --format="value(email)" 2>/dev/null || echo "")

            for SA in $SA_LIST; do
              KEYS=$(gcloud iam service-accounts keys list \
                --iam-account="$SA" \
                --project="$PROJECT" \
                --managed-by=user \
                --format="json" 2>/dev/null || echo "[]")

              KEY_COUNT=$(echo "$KEYS" | python3 -c "import json,sys; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")

              if [ "$KEY_COUNT" -gt 0 ]; then
                echo "- **${SA}**: ${KEY_COUNT} user-managed key(s) found" >> "$GITHUB_STEP_SUMMARY"

                # Check for keys older than 90 days
                echo "$KEYS" | python3 -c "
          import json, sys
          from datetime import datetime, timezone
          keys = json.load(sys.stdin)
          for k in keys:
              created = datetime.fromisoformat(k['validAfterTime'].replace('Z', '+00:00'))
              age = (datetime.now(timezone.utc) - created).days
              status = 'ROTATE NOW' if age > 90 else 'OK'
              print(f'  - Key {k[\"name\"][-8:]}: {age} days old [{status}]')
          " 2>/dev/null >> "$GITHUB_STEP_SUMMARY" || true
              else
                echo "- **${SA}**: No user-managed keys (using WIF)" >> "$GITHUB_STEP_SUMMARY"
              fi
            done
          done

          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "*Recommendation: Use Workload Identity Federation instead of SA keys.*" >> "$GITHUB_STEP_SUMMARY"
